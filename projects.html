<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Projects – Damini Kusum</title>
  <link rel="stylesheet" href="style.css?v=11">
</head>

<body>

  <nav class="nav">
  <div class="nav-inner">
    <a href="index.html" class="nav-link active">About</a>
    <a href="projects.html" class="nav-link">Projects</a>
  </div>
</nav>


  <main style="padding-top: 8vh;">
    <section class="content">
      <h1 style="text-align:center;">Projects</h1>

      <p>
        <strong>Solomonoff Induction and Algorithmic Randomness</strong><br>
        For sequential prediction tasks, Solomonoff’s celebrated result guarantees the inductive success of the “simplicity” prior by showing that the predictive probabilities induced by any optimal c.e. semimeasure converge to the posterior of the true probability almost surely. Hutter and Muchnik have shown that there exists an optimal c.e. semimeasure for which one can construct a Martin-Löf sequence along which this optimal semimeasure fails to converge to the uniform measure. Since the study of algorithmic randomness can be used to characterize “almost-sure” convergence theorems, one can ask whether stronger notions of randomness suffice for Solomonoff convergence.
        
      </p>

      <p>
      <a href="thesispdf.pdf" target="_blank">
        Download PDF
      </a>
     </p>

    </section>
  </main>

</body>
</html>
